{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed8bf913",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886263e4",
   "metadata": {},
   "source": [
    "1. Provide a problem statement or a user story. (Who is your audience in the statement or story ?)\n",
    "\n",
    "\n",
    "Problem statement: Imagine we are data analytics service provider, our client, a public health organization,want to understand and categorize COVID-19-related tweets in order to gain insights into public sentiment, misinformation, and key topics of discussion, which will help them tailor our communication strategies and public health campaigns more effectively\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890fb77",
   "metadata": {},
   "source": [
    "2. Provide intuitive explanations of ML methodology and interpretation of key metrics.\n",
    "\n",
    "\n",
    "ML methodology explanation: We use a combination of unsupervised clustering and supervised multilabel classification to categorize tweets into meaningful topics. First, we preprocess the text data by cleaning and transforming it into numerical embeddings. Next, we apply K-Means clustering to group similar tweets together. For each cluster, we generate representative keyword tags using GPT-3. We then train various multilabel classifiers, such as logistic regression, LDA, Gradient Boosting, Random Forest, and MLP, using these keyword tags as ground truth labels. To evaluate the performance of our models, we use metrics like accuracy and Hamming loss; we select the best model with relatively high accuracy and relatively low hamming loss.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a842b",
   "metadata": {},
   "source": [
    "3. Model metrics/performance is connected with real-world impact(e.g. Profit, retentionâ€¦)\n",
    "\n",
    "\n",
    "\n",
    "Real-world impact(qualitative in my case): It can help the public health organization identify trends, misinformation, and areas of public concern, allowing them to make informed decisions about communication strategies and public health campaigns. This can ultimately lead to increased public awareness, better adherence to safety guidelines, and improved public health outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fd0cb38",
   "metadata": {
    "code_folding": [
     17,
     55,
     78
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing Helper Functions\n",
    "def preprocess_text(text: str) -> str:\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes a tweet string by removing any weird string characters/formattings\n",
    "    Args: \n",
    "        - text (str): the text to clean\n",
    "    Returns: \n",
    "        - clean_text (str): the cleaned text string\n",
    "    \"\"\"\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    # Removing Emojis\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # Removing emoticons\n",
    "    text = re.sub(r':\\w+:', '', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # Removing Contractions\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    clean_text = text\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "def preprocess_nulls(df: pd.DataFrame) -> pd.DataFrame: \n",
    "    \n",
    "    \"\"\"\n",
    "    Removes nulls and 0 counts from a dataframe\n",
    "    Args: \n",
    "        - df (pd.DataFrame): the dataframe to remove nulls from\n",
    "    Returns: \n",
    "        - clean_df (str): the cleaned df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop duplicate rows \n",
    "    df = df.drop_duplicates(subset = \"text\")\n",
    "    \n",
    "    # Drop rows with no followers \n",
    "    df = df[df['user_followers'] > 0]\n",
    "    \n",
    "    # Drop nulls and reset index \n",
    "    df = df.dropna().reset_index(drop = True)\n",
    "    \n",
    "    clean_df = df\n",
    "    \n",
    "    return clean_df\n",
    "\n",
    "def preprocess_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \"\"\"\n",
    "    Main processing function on the dataframe\n",
    "    Args: \n",
    "        - df (pd.DataFrame): df of tweets to process\n",
    "    Returns: \n",
    "        - preprocessed_df (pd.DataFrame): the processed df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Preprocess null and missing values \n",
    "    df = preprocess_nulls(df)\n",
    "    \n",
    "    # Preprocess text \n",
    "    df['processed_text'] = df['text'].apply(preprocess_text)            \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6139c5",
   "metadata": {},
   "source": [
    "# EDA Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ef2e24",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocessed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreprocessed_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocessed_df' is not defined"
     ]
    }
   ],
   "source": [
    "preprocessed_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87723ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "file_path = input(\"Please enter the path to your CSV file: \")\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"\\nData is loaded successfully\")\n",
    "\n",
    "# Preprocess dataset\n",
    "preprocessed_df = preprocess_df(df)\n",
    "print(\"Your data is ready for analysis.\")\n",
    "\n",
    "\n",
    "# Dropdown menu to choose the plot\n",
    "plot_options = ['Bar Plot of Most Common Words in Tweets', 'Distribution of Length of Tweets', 'Time-series Plot of Tweet Counts', 'Word Cloud of Most Common Words']\n",
    "plot_dropdown = widgets.Dropdown(\n",
    "    options=plot_options,\n",
    "    value=plot_options[0],\n",
    "    description='Select Plot:',\n",
    ")\n",
    "\n",
    "# Dropdown menu to choose the country\n",
    "country_options = ['All Countries', 'United States', 'Canada', 'South Africa','Switzerland','London','India','United Kingdom']\n",
    "country_dropdown = widgets.Dropdown(\n",
    "    options=country_options,\n",
    "    value=country_options[0],\n",
    "    description='Select Country:',\n",
    ")\n",
    "\n",
    "# Date range picker\n",
    "start_date_picker = widgets.DatePicker(\n",
    "    description='Start Date',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "end_date_picker = widgets.DatePicker(\n",
    "    description='End Date',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "\n",
    "# Button to process the dataset and generate the plot\n",
    "process_button = widgets.Button(\n",
    "    description='Plot',\n",
    "    tooltip='Plot',\n",
    ")\n",
    "\n",
    "# Output widget to display the result\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "\n",
    "        # Filter tweets by country\n",
    "        selected_country = country_dropdown.value\n",
    "        if selected_country != 'All Countries':\n",
    "            filtered_df = preprocessed_df.loc[preprocessed_df['user_location'] == selected_country]\n",
    "        else:\n",
    "            filtered_df = preprocessed_df\n",
    "\n",
    "        \n",
    "        filtered_df['date'] = pd.to_datetime(filtered_df['date'])\n",
    "\n",
    "        start_date = start_date_picker.value\n",
    "        end_date = end_date_picker.value\n",
    "        if start_date and end_date:\n",
    "           start_date = pd.to_datetime(start_date)\n",
    "           end_date = pd.to_datetime(end_date)\n",
    "           filtered_df = filtered_df[(filtered_df['date'] >= start_date) & (filtered_df['date'] <= end_date)]\n",
    "        \n",
    "        # Plot selected graph\n",
    "        selected_plot = plot_dropdown.value\n",
    "\n",
    "        if selected_plot == 'Bar Plot of Most Common Words in Tweets':\n",
    "            # code for bar plot\n",
    "            text = \" \".join(filtered_df['processed_text'])\n",
    "            words = text.split()\n",
    "            words_counter = Counter(words)\n",
    "            most_common_words = words_counter.most_common(20)\n",
    "\n",
    "            words = [word[0] for word in most_common_words]\n",
    "            counts = [word[1] for word in most_common_words]\n",
    "\n",
    "            plt.bar(words, counts)\n",
    "            plt.xlabel('Words')\n",
    "            plt.ylabel('Frequency')\n",
    "            plt.title('Bar Plot of Most Common Words in Tweets')\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.show()\n",
    "\n",
    "        elif selected_plot == 'Distribution of Length of Tweets':\n",
    "            # code for length distribution plot\n",
    "            filtered_df['text_length'] = filtered_df['text'].apply(len)\n",
    "            filtered_df['text_length'].plot.hist(bins=30, rwidth=0.9)\n",
    "            plt.xlabel('Length of Tweets')\n",
    "            plt.ylabel('Counts')\n",
    "            plt.title('Distribution of Length of Tweets')\n",
    "            plt.show()\n",
    "            \n",
    "        elif selected_plot == 'Time-series Plot of Tweet Counts':\n",
    "            # code for time-series plot\n",
    "            filtered_df['date'] = pd.to_datetime(filtered_df['date'])\n",
    "            df_grouped = filtered_df.groupby(filtered_df['date'].dt.date).count()\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(df_grouped.index, df_grouped['text'])\n",
    "            ax.set_ylabel('Number of Tweets')\n",
    "            ax.set_title('Time-series Plot of Tweet Counts')\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.show()\n",
    "            \n",
    "        elif selected_plot == 'Word Cloud of Most Common Words':\n",
    "            # code for word cloud\n",
    "            text = \" \".join(filtered_df['processed_text'])\n",
    "            words = text.split()\n",
    "            words_counter = Counter(words)\n",
    "            wordcloud = WordCloud(width=800, height=400).generate_from_frequencies(words_counter)\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.imshow(wordcloud, interpolation='bilinear')\n",
    "            plt.axis(\"off\")\n",
    "            plt.title('Word Cloud of Most Common Words')\n",
    "            plt.show()\n",
    "            \n",
    "        else: # 'Word Cloud of Most Common Words by Location'\n",
    "            top_words_by_location = {}\n",
    "            for location in filtered_df['user_location'].unique():\n",
    "                location_df = filtered_df.loc[filtered_df['user_location'] == location]\n",
    "                text = \" \".join(location_df['processed_text'])\n",
    "                words = text.split()\n",
    "                words_counter = Counter(words)\n",
    "                most_common_words = words_counter.most_common(20)\n",
    "                top_words_by_location[location] = most_common_words\n",
    "\n",
    "            # Plot word cloud for each location\n",
    "            for location, top_words in top_words_by_location.items():\n",
    "                words = [word[0] for word in top_words]\n",
    "                frequencies = [word[1] for word in top_words]\n",
    "                wordcloud = WordCloud(width=800, height=400).generate_from_frequencies(dict(zip(words, frequencies)))\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                plt.axis(\"off\")\n",
    "                plt.title(f'Most Common Words in Tweets from {location}')\n",
    "                plt.show()\n",
    "\n",
    "process_button.on_click(on_button_click)\n",
    "\n",
    "#Display widgets\n",
    "\n",
    "display(country_dropdown)\n",
    "display(start_date_picker)\n",
    "display(end_date_picker)\n",
    "display(plot_dropdown)\n",
    "display(process_button)\n",
    "display(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014eda2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f4fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
