{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e052715",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265d71b",
   "metadata": {},
   "source": [
    "The outbreak of the pandemic has truely changed many people's life. With the loss of almost 7 million lives in the world, many people exhibited behaviors associated with the psychological shadow. Thus, the demand of psychological service might increase fast in order to ease people's emotions.\n",
    "\n",
    "Our project could be used by psychologist, for both therapist and researchers, when\n",
    "\n",
    "- Studying psychological reactions to the pandemic: Researchers can analyze tweets to understand people's emotional reactions to the pandemic, such as fear, anxiety, stress, and sadness. They can also examine how people cope with the pandemic and how they adapt to new circumstances. By studying the language people use in their tweets, researchers can gain insight into their psychological state and experiences.\n",
    "\n",
    "- Understanding social dynamics during the pandemic: Researchers can use tweets to examine how people interact with each other during the pandemic. For example, they can analyze how people express social support or criticize others for not following public health guidelines. They can also investigate how social norms change during the pandemic and how they influence people's behavior.\n",
    "\n",
    "- Identifying risk factors for mental health problems: Researchers can analyze tweets to identify risk factors for mental health problems during the pandemic. For example, they can look for patterns of language use that suggest loneliness, social isolation, or depression. They can also examine how people talk about their coping strategies and identify which strategies are associated with better mental health outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e180b6ca",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38e48fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "from IPython.display import display\n",
    "from ipywidgets import (interact, Dropdown, SelectMultiple,\n",
    "                        IntSlider, ToggleButtons, DatePicker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76dc3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/covid2023.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b143d5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62d88879d06b416baa1cdb1b23f520f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(DatePicker(value=datetime.datetime(2023, 1, 1, 0, 0), description='Start Date', step=1),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_array = pd.date_range(start='2022-01-01', end='2022-12-31', freq='D')\n",
    "value_array = range(len(date_array))\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "    'date': date_array,\n",
    "    'value': value_array\n",
    "})\n",
    "\n",
    "\n",
    "# Define start and end date pickers\n",
    "start_date_picker = widgets.DatePicker(\n",
    "    description='Start Date',\n",
    "    value=datetime.datetime(2023, 1, 1),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "end_date_picker = widgets.DatePicker(\n",
    "    description='End Date',\n",
    "    value=datetime.datetime(2023, 1, 1),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def filter_dataframe(start_date, end_date):\n",
    "    if start_date is None or end_date is None:\n",
    "        print(\"Please select start and end dates.\")\n",
    "        return\n",
    "    try:\n",
    "        start_date = pd.to_datetime(start_date)\n",
    "        end_date = pd.to_datetime(end_date)\n",
    "    except ValueError:\n",
    "        print(\"Please enter dates in yyyy-mm-dd format.\")\n",
    "        return\n",
    "    if not isinstance(df1['date'], pd.DatetimeIndex):\n",
    "        print(\"The 'date' column is not a datetime object.\")\n",
    "        return\n",
    "    filtered_df = df1[(df1['date'] >= start_date) & (df1['date'] <= end_date)]\n",
    "    display(filtered_df)\n",
    "\n",
    "    \n",
    "# Create an interaction between the date pickers and the filter function\n",
    "widgets.interact(filter_dataframe, start_date=start_date_picker, end_date=end_date_picker);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16b4b1a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce9714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from seaborn) (1.23.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/bennettcohen/miniconda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcb8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "### basic cleaning of the data\n",
    "\n",
    "# drop duplicates\n",
    "df = df.drop_duplicates(subset='text')\n",
    "# drop the rows that user_followers =0\n",
    "df = df[df['user_followers'] != 0]\n",
    "# drop NA values\n",
    "df = df.dropna()\n",
    "# reset index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# preprocess the text column and do text cleaning(most common methods are covered)\n",
    "def preprocess_text(text):\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    \n",
    "    # remove numbers\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    \n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Removing extra spaces\n",
    "    text = \" \".join(tokens)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    # Removing Emojis\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "    \n",
    "    # Removing emoticons\n",
    "    text = re.sub(r':\\w+:', '', text)\n",
    "    \n",
    "    # Removing Contractions\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(preprocess_text)\n",
    "\n",
    "def remove_emojis(column):\n",
    "    return re.sub(r'[^\\x00-\\x7F]+', '', column)\n",
    "\n",
    "df[\"user_name\"] = df[\"user_name\"].apply(remove_emojis)\n",
    "df[\"user_location\"] = df[\"user_location\"].apply(remove_emojis)\n",
    "df[\"user_description\"] = df[\"user_description\"].apply(remove_emojis)\n",
    "\n",
    "\n",
    "# check the distribution of tweet length\n",
    "df[\"tweet_length\"] = df[\"text\"].apply(len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc83479",
   "metadata": {},
   "outputs": [],
   "source": [
    "## impletement date selection\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date']).dt.tz_localize(None)\n",
    "\n",
    "if start_date_picker.value is not None and end_date_picker.value is not None:\n",
    "    start_date = pd.to_datetime(start_date_picker.value)\n",
    "    end_date = pd.to_datetime(end_date_picker.value)\n",
    "\n",
    "    # filter the dataframe\n",
    "    filtered_df = df[(df['data_date'] >= start_date) & (df['data_date'] <= end_date)]\n",
    "else:\n",
    "    filtered_df = df.copy()\n",
    "\n",
    "# filter the dataframe\n",
    "filtered_df = df[(df['data_date'] >= start_date) & (df['data_date'] <= end_date)]\n",
    "\n",
    "print(start_date, end_date)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bd7606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87498bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b02214",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575de79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text = \" \".join(filtered_df['text'])\n",
    "words = text.split()\n",
    "words_counter = Counter(words)\n",
    "most_common_words = words_counter.most_common(20)\n",
    "\n",
    "words = [word[0] for word in most_common_words]\n",
    "counts = [word[1] for word in most_common_words]\n",
    "\n",
    "plt.bar(words, counts)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Bar Plot of Most Common Words in Tweets within Time Selection')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cf4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "\n",
    "# Clean the user_location column\n",
    "filtered_df['user_location'] = filtered_df['user_location'].str.replace('[^\\w\\s]','')\n",
    "filtered_df = filtered_df[filtered_df['user_location'].notna()]\n",
    "text = \" \".join(filtered_df['user_location'].values)\n",
    "\n",
    "# Create the word cloud\n",
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "                background_color ='white', \n",
    "                stopwords = None, \n",
    "                min_font_size = 10).generate(text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\") \n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166dd006",
   "metadata": {},
   "source": [
    "The bar plot could give the psychologist the most popular twitter words used within the time period, and the word cloud could give the most common location within this time period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1f350",
   "metadata": {},
   "source": [
    "## Data Pick Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b38734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "vader_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c750fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pick from selected date\n",
    "import datetime\n",
    "\n",
    "df.loc[:, \"data_date\"] = \\\n",
    "    pd.to_datetime(df[\"date\"]).dt.date\n",
    "\n",
    "#date_picker = widgets.DatePicker(name='Date Picker',start= s, end= e,value=datetime.datetime(df[0][\"date\"])\n",
    "date_picker = widgets.DatePicker(description='Select Date',value=datetime.datetime(2023, 1, 1))\n",
    "\n",
    "\n",
    "@interact(date=date_picker)\n",
    "def order_by_date(date):\n",
    "    pick_data = df.loc[\n",
    "        (df[\"data_date\"] == date)\n",
    "    ]\n",
    "    if len(pick_data) == 0:\n",
    "        return print (\"Choose different day\")\n",
    "    print(f\"{len(pick_data)=}\\n\")\n",
    "    return pick_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b593ec5",
   "metadata": {},
   "source": [
    "## Sentimental score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729800be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#date_picker = widgets.DatePicker(start=datetime.datetime(2023, 1, 31), end=datetime.datetime(2023, 2, 8)value)\n",
    "date_picker = widgets.DatePicker(description='Select Date',value=datetime.datetime(2023, 1, 1))\n",
    "\n",
    "@interact(input_date=date_picker)\n",
    "#def sentimental(start_date, end_date): \n",
    "def sentimental(input_date): \n",
    "    \n",
    "    if (isinstance(input_date, date)):\n",
    "        filtered_df = df[(df['data_date'] == input_date)]\n",
    "    else:\n",
    "        filtered_df = df[(df['data_date'] >= input_date.date()) & (df['data_date'] <= input_date.date())]\n",
    "        \n",
    "    print (\"Data count = \" , len(filtered_df))\n",
    "    sentences23 = filtered_df['text']\n",
    "    date23 = filtered_df['date']\n",
    "    \n",
    "    if len(date23) == 0:\n",
    "        return print (\"Choose different day\")\n",
    "    else:\n",
    "        result = []\n",
    "        df23 = pd.DataFrame()\n",
    "        for s in sentences23:\n",
    "            score = vader_analyzer.polarity_scores(s)\n",
    "            result.append(score)\n",
    "\n",
    "        i = 0\n",
    "        for i in range(len(result)):\n",
    "            x = pd.DataFrame.from_dict(result[i], orient='index').T\n",
    "            df23 = pd.concat([df23,x], ignore_index=True)\n",
    "        df23.index = sentences23\n",
    "        \n",
    "        return plt.hist( df23[\"compound\"],bins =30)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98716637",
   "metadata": {},
   "source": [
    "## hashtag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42347c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hashtag_list = df[\"hashtags\"].tolist()\n",
    "#hashtag_list_0 = SelectMultiple(options=hashtag_list,discription=\"hashtag\")\n",
    "#hashtag_list_0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb61ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b6ccad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
